{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXtdS6ki2AqJ"
      },
      "source": [
        "> <p><small><small>This Notebook is made available subject to the licence and terms set out in the <a href = \"http://www.github.com/google-deepmind/ai-foundations\">AI Research Foundations Github README file</a>."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edg_yBoO2Dc2"
      },
      "source": [
        "![](https://storage.googleapis.com/dm-educational/assets/ai_foundations/GDM-Labs-banner-image-C4-white-bg.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iLop_P72KwS"
      },
      "source": [
        "# Lab: Visualizing Attention Weights\n",
        "\n",
        "<a href='https://colab.research.google.com/github/google-deepmind/ai-foundations/blob/master/course_4/gdm_lab_4_1_attention_visualization.ipynb' target='_parent'><img src='https://colab.research.google.com/assets/colab-badge.svg' alt='Open In Colab'/></a>\n",
        "\n",
        "Explore how transformer attention weights highlight which tokens influence predictions.\n",
        "\n",
        "10 minutes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7fZa-AxFuRl"
      },
      "source": [
        "## Overview\n",
        "\n",
        "In this lab, you will explore how transformer models make their predictions. Transformer models rely heavily on a so-called **attention mechanism**. This mechanism allows the model to build contextual embeddings that combine information from all tokens in the prompt. When training a transformer model, this mechanism learns how much each token in the prompt should be attended to. That is, how much weight should be placed on the information of each token when building a contextual embedding to predict the next token.\n",
        "\n",
        "\n",
        "Unlike in the pen-and-paper exercise you did at the beginning of this course, transformer models do not decide just once which tokens are important. Instead, they have many **layers** and the attention mechanism operates on each layer. For example, the Gemma-1B model has 26 layers.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Whd5_duQA1no"
      },
      "source": [
        "### What you will learn  \n",
        "By the end of this lab, you will:  \n",
        "* Understand how attention weights indicate which tokens contribute most to predicting the next token.  \n",
        "* Understand how attention can cross sentence boundaries and capture context from earlier sentences.  \n",
        "\n",
        "### Tasks  \n",
        "In this lab, you will:\n",
        "* Visualize the attention weights in different layers of the Gemma-1B model for different prompts.\n",
        "* Investigate the attention weights for prompts spanning multiple sentences.\n",
        "\n",
        "If you are able to, we recommend running the code in this lab on **a Colab instance with a GPU**. See the section \"How to use Google Colaboratory (Colab)\" below for instructions on how to do this."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yi1rXXujBSHq"
      },
      "source": [
        "## How to use Google Colaboratory (Colab)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaB_nYaZBS8i"
      },
      "source": [
        "Google Colaboratory (also known as Google Colab) is a platform that allows you to run Python code in your browser. The code is written in **cells** that are executed on a remote server.\n",
        "\n",
        "To run a cell, hover over the cell and click on the `run` button to its left. The run button is the circle with the triangle (â–¶). Alternatively, you can also click on a cell and use the keyboard combination Ctrl+Return (or âŒ˜+Return if you are using a Mac).\n",
        "\n",
        "To try this out, run the following cell. This should print today's day of the week below it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6YaJgmApBVip"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "print(f\"Today is {datetime.today():%A}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ou6ngVN2BYjG"
      },
      "source": [
        "Note that the *order in which you run the cells matters*. When you are working through a lab, make sure to always run *all* cells in order, otherwise the code might not work. If you take a break while working on a lab, Colab may disconnect you and in that case, you have to execute all cells again before  continuing your work. To make this easier, you can select the cell you are currently working on and then choose __Runtime â†’ Run before__  from the menu above (or use the keyboard combination Ctrl/âŒ˜ + F8). This will re-execute all cells before the current one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLvkcx5pUItk"
      },
      "source": [
        "### Using Colab with a GPU\n",
        "\n",
        "A **GPU** is a special type of hardware that can significantly speed up some types of computations of machine learning models. Several of the activities in this lab will also run a lot faster if you run them on a GPU.\n",
        "\n",
        "Follow these steps to run the activities in this lab on a GPU:\n",
        "\n",
        "1.  In the top menu bar, click on **Runtime**.\n",
        "2.  Select **Change runtime type** from the dropdown menu.\n",
        "3.  In the pop-up window under **Hardware Accelerator**, select **GPU** (usually listed as `T4 GPU`).\n",
        "5.  Click **Save**.\n",
        "\n",
        "Your Colab session will now restart with GPU access.\n",
        "\n",
        "Note that access to GPUs is limited and at times, you may not be able to run this lab on a GPU. All activities will still work but they will run slower and you will have to wait longer for some of the cells to finish running.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kku7-jWFBfjU"
      },
      "source": [
        "## Imports\n",
        "\n",
        "In this lab, you will make use of the custom `ai_foundations` package that provides methods for loading Gemma-1B and visualizing its attention weights.\n",
        "\n",
        "Run the following cell to import the required packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-n8Ve9OQ0_md"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "# Install the custom package for this course.\n",
        "!pip install orbax-checkpoint==0.11.21\n",
        "!pip install \"git+https://github.com/google-deepmind/ai-foundations.git@main\"\n",
        "\n",
        "from ai_foundations import generation # For loading and prompting Gemma.\n",
        "from ai_foundations import visualizations # For attention weight visualization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DBuL-OVkKZr"
      },
      "source": [
        " ## Load the model\n",
        "\n",
        "Run the following cell to load the Gemma-1B model. You will use this model to generate the next token and compute its attention weights. This cell also initializes a cache that speeds up the visualizations if you only adjust the layer parameter.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5JQVQDC1rKo"
      },
      "outputs": [],
      "source": [
        "# Initialize caches for prompts.\n",
        "previous_prompt = None\n",
        "previous_prompt2 = None\n",
        "\n",
        "# Load special version of the Gemma-1B model that provides access to attention\n",
        "# weights.\n",
        "print(\"Loading Gemma-1B...\")\n",
        "model = generation.load_gemma(\"Gemma-1B-AttentionWeight\")\n",
        "print(\"Loaded Gemma-1B.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gZ2zyuQgxkr"
      },
      "source": [
        "## Visualize attention weights for single-sentence prompts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdB7VKCChgjQ"
      },
      "source": [
        "------\n",
        "> **ðŸ’» Your task:**\n",
        ">1. Enter a prompt below and run the cell to visualize the attention weights for a specific layer.\n",
        ">2. Investigate how the weights change across layers. Does the model attend to the same tokens in each layer? Do the attention weights line up with what you think is important for making predictions?\n",
        ">3. Investigate how the weights change if you add or remove words from the prompt.\n",
        ">\n",
        "> The code below generates a figure that shows how much the representation of each token in the prompt  matters for the prediction of the generated token. The thicker the line, the more the token representation influences the prediction of the next token at that layer.\n",
        ">\n",
        "> Note that transformer language models often put a high weight on the first token, the special beginning of sequence (BOS) token (reference, e.g., [Analyzing the Structure of Attention in a Transformer Language Model](https://aclanthology.org/W19-4808/) [1]). The visualizations below therefore show the lines to the BOS token (`<BOS>`) in gray to make it easier to see the other connections.\n",
        "------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2mJNICDcxgWH"
      },
      "outputs": [],
      "source": [
        "# @title Visualize attention weights\n",
        "layer = 19  # @param {type:\"slider\", min: 0, max: 25}\n",
        "\n",
        "prompt = \"Jide was hungry so she went looking for\"  # @param {type: \"string\"}\n",
        "\n",
        "show_all_weights = False\n",
        "\n",
        "\n",
        "if prompt != previous_prompt:\n",
        "    (output_text, next_token_logits, tokenizer, attention_weights, _, _) = (\n",
        "        generation.prompt_attention_transformer_model(\n",
        "            prompt, model, sampling_mode=\"greedy\"\n",
        "        )\n",
        "    )\n",
        "    tokens = [tokenizer.tokens[t] for t in tokenizer.encode(output_text)]\n",
        "    previous_prompt = prompt\n",
        "\n",
        "print(f\"Generated text: {output_text}\")\n",
        "\n",
        "visualizations.visualize_attention(\n",
        "    tokens,\n",
        "    attention_weights[f\"layer_{layer}\"],\n",
        "    layer,\n",
        "    min_line_thickness=0,\n",
        "    max_line_thickness=5,\n",
        "    show_all_weights=show_all_weights\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ka-9uvYmnpdA"
      },
      "source": [
        "### What did you observe?\n",
        "\n",
        "For the prompt \"Jide was hungry so she went looking for\" the model predicted the token \"food\" as the most likely next token. In some layers (e.g., layer 19), this prediction depends a lot on the token \"hungry\". In others (e.g., layer 2), this prediction depends a lot on the very local context, such as \"looking for\".\n",
        "\n",
        "When you modified the prompt, you likely found similar patterns. For example, if you changed the prompt to \"Jide was thirsty so she went looking for\", you likely observed that in layer 19, the model relies a lot on the token \"thirsty\" for predicting the next token \"water\".\n",
        "\n",
        "These similarities are no coincidence. As you will learn more about later in this course, attention mechanisms in different layers tend to focus on different dependencies between tokens."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_wtvwGGMqKf"
      },
      "source": [
        "## Visualize attention across sentence boundaries\n",
        "\n",
        "Transformer models also consider tokens in previous sentences as long as they are part of the same prompt. In this activity, you will visualize the attention weights of longer prompts.\n",
        "\n",
        "<br />\n",
        "\n",
        "------\n",
        "> **ðŸ’» Your task:**\n",
        ">\n",
        ">1. Enter a prompt below that spans multiple sentences. For example, you can copy the following short text from the previous exercise:\n",
        ">\n",
        ">    \"The artist selected a shade of blue from her palette. With a steady hand, she began to paint the waves onto the canvas. She wanted to capture the power and beauty of the\"\n",
        ">\n",
        ">2. Investigate which tokens are most important for making predictions. Are they all from the same sentence?\n",
        ">3. Compare the weights for the prompt above to the weights of this prompt.\n",
        ">    * In which layers do you see similar behaviors, regardless of the different text?\n",
        ">    * Identify a layer focused on semantic meaning. How does it weigh tokens that are most important for understanding the context?\n",
        ">    * Now, find a layer focused on grammaticality. How does it weigh tokens that are most important to ensure the sentence is grammatical?\n",
        ">\n",
        "------\n",
        "<br>\n",
        "\n",
        "_Note: If the visualization is difficult to read, click it to make it bigger._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-Ol7vD-hMoqs"
      },
      "outputs": [],
      "source": [
        "# @title Visualize attention weights\n",
        "layer = 19  # @param {type:\"slider\", min: 0, max: 25}\n",
        "\n",
        "prompt = \"The artist selected a shade of blue from her palette. With a steady hand, she began to paint the waves onto the canvas. She wanted to capture the power and beauty of the\"  # @param {type: 'string'}\n",
        "show_all_weights = False\n",
        "\n",
        "\n",
        "if prompt != previous_prompt2:\n",
        "    (output_text2, next_token_logits2, tokenizer, attention_weights2, _, _) = (\n",
        "        generation.prompt_attention_transformer_model(\n",
        "            prompt, model, sampling_mode=\"greedy\"\n",
        "        )\n",
        "    )\n",
        "\n",
        "    tokens2 = [tokenizer.tokens[t] for t in tokenizer.encode(output_text2)]\n",
        "    previous_prompt2 = prompt\n",
        "\n",
        "print(f\"Generated text: {output_text2}\")\n",
        "\n",
        "visualizations.visualize_attention(\n",
        "    tokens2,\n",
        "    attention_weights2[f\"layer_{layer}\"],\n",
        "    layer,\n",
        "    min_line_thickness=0,\n",
        "    max_line_thickness=5,\n",
        "    show_all_weights=show_all_weights,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AjRCBdrRMDy"
      },
      "source": [
        "Inspect the attention weights for a few more sentences. Do they match your intuitions? Are there any patterns you find surprising?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3haEBbGzrpBi"
      },
      "source": [
        "## Summary\n",
        "\n",
        "In this brief activity, you visualized the **attention weights** of the Gemma-1B model for a range of prompts. You observed that there are certain tokens that are more important for predicting the next token than others, and that this set of tokens can change across layers. You also experimented with longer prompts and observed that the prediction of the next token can also depend on tokens in previous sentences.\n",
        "\n",
        "In the next activities, you will learn more about the architecture of the transformer model, how it computes its attention weights and how the attention weights are used to compute contextual embeddings for predicting the next token."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-lZOqy8mOLV"
      },
      "source": [
        "## References\n",
        "\n",
        "[1] Jesse Vig and Yonatan Belinkov. 2019. Analyzing the Structure of Attention in a Transformer Language Model. In *Proceedings of the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP*. Retrieved from https://aclanthology.org/W19-4808/."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Yi1rXXujBSHq"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}